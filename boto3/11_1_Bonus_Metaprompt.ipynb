{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1mtyzbvpM2L"
   },
   "source": [
    "# Metaprompt\n",
    "Welcome to the Metaprompt! This is a prompt engineering tool designed to solve the \"blank page problem\" and give you a starting point for iteration. All you need to do is enter your task, and optionally the names of the variables you'd like Claude to use in the template. Then you'll be able to run the prompt that comes out on any examples you like.\n",
    "\n",
    "**Caveats**\n",
    "- This is designed for single-turn question/response prompts, not multiturn.\n",
    "- The Metaprompt is designed for use with **Claude 3 Opus.** Generating prompts with other models may lead to worse results.\n",
    "- The prompt you'll get at the end is not guaranteed to be optimal by any means, so don't be afraid to change it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOYnM7A3g6HB"
   },
   "source": [
    "### Using This Notebook\n",
    "The notebook is designed to be maximally easy to use. You don't have to write any code. Just follow these steps:\n",
    "- Enter your Anthropic API key in between quotation marks where it says \"Put your API key here!\"\n",
    "- Enter your task where it says \"Replace with your task!\"\n",
    "- Optionally, enter an all-caps list of variables in quotes separated by commas where it says \"specify the input variables you want Claude to use\".\n",
    "\n",
    "Then, you can simply click \"Runtime -> Run all\" and your prompt will be displayed at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic --quiet\n",
    "\n",
    "# set path to import the meta module that contains the metaprompt\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "import boto3\n",
    "session = boto3.Session() # create a boto3 session to dynamically get and set the region name\n",
    "AWS_REGION = session.region_name\n",
    "print(\"AWS Region:\", AWS_REGION)\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "\n",
    "from anthropic import AnthropicBedrock\n",
    "CLIENT = AnthropicBedrock(aws_region=AWS_REGION)\n",
    "MODEL_NAME='anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "%store MODEL_NAME\n",
    "%store AWS_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Rj3kLi4ALGKf"
   },
   "outputs": [],
   "source": [
    "import anthropic, re\n",
    "ANTHROPIC_API_KEY = \"\" # Put your API key here!\n",
    "MODEL_NAME = \"claude-3-opus-20240229\"\n",
    "CLIENT = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ-pJY_ZqtGE"
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "0. The Metaprompt\n",
    "1. Quickstart - Enter a task, get a prompt template\n",
    "2. Testing your prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBbTQMwMqcUT"
   },
   "source": [
    "## 0. The Metaprompt\n",
    "\n",
    "The Metaprompt is a long multi-shot prompt filled with half a dozen examples of good prompts for solving various tasks. These examples help Claude to write a good prompt for your task. The full text is below (warning: it's long!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "NTOiFKNxqoq2"
   },
   "outputs": [],
   "source": [
    "# import the meta module from the utils package\n",
    "# see utils/metap.py for the implementation\n",
    "# Import the metap module from the utils package\n",
    "from utils import meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RGDChQBsgKa"
   },
   "source": [
    "# 1. Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StAFtG7Cskn2"
   },
   "source": [
    "Enter your task in the cell below. Here are some examples for inspiration:\n",
    "- Choose an item from a menu for me given user preferences\n",
    "- Rate a resume according to a rubric\n",
    "- Explain a complex scientific concept in simple terms\n",
    "- Draft an email responding to a customer complaint\n",
    "- Design a marketing strategy for launching a new product\n",
    "\n",
    "There are two examples of tasks + optional variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XPySubcpKiwg"
   },
   "outputs": [],
   "source": [
    "TASK = \"Draft an email responding to a customer complaint\" # Replace with your task!\n",
    "# Optional: specify the input variables you want Claude to use. If you want Claude to choose, you can set `variables` to an empty list!\n",
    "# VARIABLES = []\n",
    "VARIABLES = [\"CUSTOMER_EMAIL\", \"COMPANY_NAME\"]\n",
    "# If you want Claude to choose the variables, just leave VARIABLES as an empty list.\n",
    "\n",
    "# TASK = \"Choose an item from a menu for me given my preferences\"\n",
    "# VARIABLES = []\n",
    "# VARIABLES = [\"MENU\", \"PREFERENCES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKxOMb4Wrh9T",
    "outputId": "9247da39-aa8a-484e-e22b-36b956d81641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{CUSTOMER_EMAIL}\n",
      "{COMPANY_NAME}\n"
     ]
    }
   ],
   "source": [
    "variable_string = \"\"\n",
    "for variable in VARIABLES:\n",
    "    variable_string += \"\\n{\" + variable.upper() + \"}\"\n",
    "print(variable_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIUwWJwfs_mp"
   },
   "source": [
    "Next, we'll insert your task into the metaprompt and see what Claude gives us! Expect this to take 20-30 seconds because the Metaprompt is so long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ihxetJAns9fo"
   },
   "outputs": [],
   "source": [
    "prompt = meta.metaprompt.replace(\"{{TASK}}\", TASK)\n",
    "assistant_partial = \"<Inputs>\"\n",
    "if variable_string:\n",
    "    assistant_partial += variable_string + \"\\n</Inputs><Instructions Structure>\"\n",
    "\n",
    "message = CLIENT.messages.create(\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=4096,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":  prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_partial\n",
    "        }\n",
    "    ],\n",
    "    temperature=0\n",
    ").content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzuwEYDQCdq9"
   },
   "source": [
    "If you want to see the full text returned by the Metaprompt to see how it planned things out, uncomment out the \"pretty_print(message)\" line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WlaPmC6QCcYO"
   },
   "outputs": [],
   "source": [
    "def pretty_print(message):\n",
    "    print('\\n\\n'.join('\\n'.join(line.strip() for line in re.findall(r'.{1,100}(?:\\s+|$)', paragraph.strip('\\n'))) for paragraph in re.split(r'\\n\\n+', message)))\n",
    "# pretty_print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HddM0hwBChTu"
   },
   "source": [
    "Now, we'll extract the prompt itself and the variables needed, while also removing empty tags at the end of the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fIBhAFs4BFIA"
   },
   "outputs": [],
   "source": [
    "def extract_between_tags(tag: str, string: str, strip: bool = False) -> list[str]:\n",
    "    ext_list = re.findall(f\"<{tag}>(.+?)</{tag}>\", string, re.DOTALL)\n",
    "    if strip:\n",
    "        ext_list = [e.strip() for e in ext_list]\n",
    "    return ext_list\n",
    "\n",
    "def remove_empty_tags(text):\n",
    "    return re.sub(r'<(\\w+)></\\1>$', '', text)\n",
    "\n",
    "def extract_prompt(metaprompt_response):\n",
    "    between_tags = extract_between_tags(\"Instructions\", metaprompt_response)[0]\n",
    "    return remove_empty_tags(remove_empty_tags(between_tags).strip()).strip()\n",
    "\n",
    "def extract_variables(prompt):\n",
    "    pattern = r'{([^}]+)}'\n",
    "    variables = re.findall(pattern, prompt)\n",
    "    return set(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plutfqqfQzdB"
   },
   "source": [
    "Below: the variables Claude chose (if you didn't provide any; if you did, these should just be the same ones you provided), and the prompt it wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GPCY1eanBFpX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "\n",
      "{'COMPANY_NAME', 'CUSTOMER_EMAIL'}\n",
      "\n",
      "************************\n",
      "\n",
      "Prompt:\n",
      "You will be drafting an email response to a customer complaint on behalf of a company. Here is the\n",
      "full text of the email the customer sent to the company:\n",
      "\n",
      "<customer_email>\n",
      "{CUSTOMER_EMAIL}\n",
      "</customer_email>\n",
      "\n",
      "You are responding as a representative of the following company: {COMPANY_NAME}\n",
      "\n",
      "First, carefully read through the customer's email. Identify the key issues, complaints, and\n",
      "problems the customer is writing about. Consider the situation from their perspective.\n",
      "\n",
      "Next, take a moment to brainstorm potential solutions, remedies and responses you could offer to\n",
      "address each of the customer's concerns. Think about what could be done to make the situation right.\n",
      "\n",
      "Now draft a response email to the customer that does the following:\n",
      "\n",
      "- Acknowledges each of their complaints and expresses understanding of why they are upset\n",
      "- Sincerely apologizes for any issues, problems or negative experiences they had\n",
      "- Addresses each of their concerns in turn, offering a specific solution or course of action for\n",
      "each one\n",
      "- If some kind of compensation, refund or make-good is warranted based on the situation, offer that\n",
      "- Thank them for taking the time to provide their feedback and for their valued patronage\n",
      "- Invite them to reply back or contact you if they have any other issues\n",
      "\n",
      "Throughout your email, maintain a professional, understanding and non-defensive tone. The goal is to\n",
      "turn a negative customer experience into a positive one through thoughtful customer service.\n",
      "Empathize with their concerns and frustrations. Take responsibility where appropriate rather than\n",
      "making excuses.\n",
      "\n",
      "Please output your draft response email inside <email> tags.\n"
     ]
    }
   ],
   "source": [
    "extracted_prompt_template = extract_prompt(message)\n",
    "variables = extract_variables(message)\n",
    "\n",
    "print(\"Variables:\\n\\n\" + str(variables))\n",
    "print(\"\\n************************\\n\")\n",
    "print(\"Prompt:\")\n",
    "pretty_print(extracted_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gac-QSTZLOKP"
   },
   "source": [
    "# 2. Testing your prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4x_S5sKDIKL"
   },
   "source": [
    "If you like your prompt, try it out! The cell will prompt you to add values for each variable. Then, it will be sent to Claude and you'll see Claude's final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rxIptUr5aZ6J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter value for variable: COMPANY_NAME\n",
      "AnthropiCouch Inc.\n",
      "Enter value for variable: CUSTOMER_EMAIL\n",
      "Your couch, while splendidly comfortable, was quite appealing to my cat as a chew toy.\n",
      "Claude's output on your prompt:\n",
      "\n",
      "\n",
      "Here is my draft response email:\n",
      "\n",
      "<email>\n",
      "Dear [Customer's Name],\n",
      "\n",
      "Thank you for reaching out to us about your recent experience with one of our AnthropiCouch\n",
      "products. I'm very sorry to hear that your cat has been treating our couch as a chew toy. I can\n",
      "certainly understand your frustration with this situation.\n",
      "\n",
      "As the manufacturer, we take great pride in crafting high-quality, durable furniture that is meant\n",
      "to withstand the rigors of everyday life, including the occasional playful pet. However, it seems we\n",
      "may have fallen short in this case, and for that I sincerely apologize.\n",
      "\n",
      "To make this right, I would be happy to send you a complimentary pet-safe furniture spray that can\n",
      "help deter cats from chewing on the couch. This spray contains natural citrus oils that cats find\n",
      "unpleasant, without harming the couch material or your pet. I'm confident this will resolve the\n",
      "issue and allow your cat to enjoy the couch in a more appropriate way.\n",
      "\n",
      "In addition, I would like to offer you a 20% discount on your next AnthropiCouch purchase. Our\n",
      "couches are designed with comfort and durability in mind, and I hope you'll give us another try.\n",
      "Your satisfaction is extremely important to us.\n",
      "\n",
      "Please let me know if there is anything else I can do to address your concerns. We value your\n",
      "business and appreciate you taking the time to provide this feedback. It will help us continue\n",
      "improving our products and customer service.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "Customer Service Representative\n",
      "AnthropiCouch Inc.\n",
      "</email>\n"
     ]
    }
   ],
   "source": [
    "variable_values = {}\n",
    "for variable in variables:\n",
    "    print(\"Enter value for variable:\", variable)\n",
    "    variable_values[variable] = input()\n",
    "\n",
    "prompt_with_variables = extracted_prompt_template\n",
    "for variable in variable_values:\n",
    "    prompt_with_variables = prompt_with_variables.replace(\"{\" + variable + \"}\", variable_values[variable])\n",
    "\n",
    "message = CLIENT.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=4096,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":  prompt_with_variables\n",
    "        },\n",
    "    ],\n",
    ").content[0].text\n",
    "\n",
    "print(\"Claude's output on your prompt:\\n\\n\")\n",
    "pretty_print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e179Irl2HwSm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
